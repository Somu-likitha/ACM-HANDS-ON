{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9493b27-f8c3-4300-ac81-abca6b5a4f8f",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "## What is PyTorch?\n",
    "\n",
    "PyTorch is an open-source machine learning library developed by Facebook's AI Research lab (FAIR). It is widely used for deep learning applications and has gained popularity for its flexibility and dynamic computation graph, distinguishing it from other frameworks. PyTorch provides a seamless interface for building and training neural networks, making it a preferred choice for both researchers and practitioners.\n",
    "\n",
    "## Why PyTorch?\n",
    "\n",
    "1. **Intuitive and Pythonic API:**\n",
    "   The PyTorch API is designed to be intuitive and Pythonic, making it easier for users to understand and work with. This reduces the learning curve for those new to deep learning.\n",
    "\n",
    "2. **Research-Focused:**\n",
    "   PyTorch is widely embraced in the research community due to its flexibility and ease of experimentation. Many cutting-edge research papers and models are released with PyTorch implementations.\n",
    "\n",
    "3. **Growing Ecosystem:**\n",
    "   The PyTorch ecosystem is continually expanding, with tools and extensions for various applications, including computer vision, natural language processing, and reinforcement learning.\n",
    "\n",
    "4. **Strong Community Support:**\n",
    "   PyTorch has a large and active community, contributing to its rich ecosystem of libraries, tutorials, and resources. This community support is valuable for both beginners and experienced practitioners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc106f33-0121-49e8-909b-4f3e7d79f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_accuracy\n",
    "from mnist import Train, Val\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde5b710-1f49-4903-8fb4-2779104c6df5",
   "metadata": {},
   "source": [
    "# PyTorch Tensors\n",
    "\n",
    "## What are Tensors?\n",
    "\n",
    "In PyTorch, a tensor is a multi-dimensional array, similar to NumPy arrays. Tensors are the fundamental building blocks for constructing neural networks and conducting operations in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f0d87-9a63-4b6b-97be-c337fb9c0767",
   "metadata": {},
   "source": [
    "### Defining Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fd397-faa2-4e16-9eb5-e4f81d6ffb77",
   "metadata": {},
   "source": [
    "#### From Python List\n",
    "\n",
    "You can create a PyTorch tensor from a Python list using the `torch.tensor()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbec8ea-58e4-45eb-9ad2-8b61bb79aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_list = [1, 2, 3, 4, 5]\n",
    "tensor_from_list = torch.tensor(python_list)\n",
    "print(tensor_from_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b9695-7f4d-42da-a440-4fb54298134f",
   "metadata": {},
   "source": [
    "#### From NumPy Arrays\n",
    "\n",
    "Conversion from NumPy arrays to PyTorch tensors is seamless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9da4d6-11c0-41f0-a9fa-96f83a84fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "tensor_from_numpy = torch.tensor(numpy_array)\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd4dcc-848a-4803-95c2-8a27df226a4c",
   "metadata": {},
   "source": [
    "#### Using `torch.ones` and `torch.zeros`\n",
    "\n",
    "Create tensors filled with ones or zeros using `torch.ones` and `torch.zeros`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a77f0b-db63-4d61-9226-1029856855c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_tensor = torch.ones((3, 3))\n",
    "zeros_tensor = torch.zeros((2, 4))\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c6c083-b7a2-4bea-9a43-7e62918fd16a",
   "metadata": {},
   "source": [
    "### Various Types of Random Initializations\n",
    "\n",
    "PyTorch provides functions for random initialization, and two commonly used ones are `torch.rand` and `torch.randn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a65a6f-07ee-4886-8a23-fce6b889d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_uniform_tensor = torch.rand((3, 3))\n",
    "random_normal_tensor = torch.randn((3, 3))\n",
    "print(random_uniform_tensor)\n",
    "print(random_normal_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73782966-1da8-4a7f-9fb8-8f2d5036bc33",
   "metadata": {},
   "source": [
    "#### Uniform Distribution - `torch.rand`\n",
    "\n",
    "`torch.rand` creates a tensor with values uniformly sampled from the interval [0, 1). Let's visualize this distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82570230-c91c-46bd-a842-256c28b9336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random values from a uniform distribution\n",
    "random_uniform_tensor = torch.rand((10_000,))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(random_uniform_tensor.numpy(), bins=50, color='tab:blue', edgecolor = \"black\")\n",
    "plt.title('Uniform Distribution (torch.rand)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c111644-d458-4288-9c73-7ad26637e2c3",
   "metadata": {},
   "source": [
    "#### Standard Normal Distribution - `torch.randn`\n",
    "\n",
    "`torch.randn` creates a tensor with values sampled from a standard normal distribution (mean=0, std=1). Let's visualize this distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8413b1-c881-48d1-b817-4f4125c9eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random values from a standard normal distribution\n",
    "random_normal_tensor = torch.randn((10_000,), )\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(random_normal_tensor.numpy(), bins=50, color='tab:blue', edgecolor = \"black\")\n",
    "plt.title('Standard Normal Distribution (torch.randn)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0be5fc-8962-4d0d-9b7e-608b462833e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T07:39:25.989789Z",
     "iopub.status.busy": "2023-12-21T07:39:25.989084Z",
     "iopub.status.idle": "2023-12-21T07:39:26.003498Z",
     "shell.execute_reply": "2023-12-21T07:39:26.001058Z",
     "shell.execute_reply.started": "2023-12-21T07:39:25.989722Z"
    }
   },
   "source": [
    "### Exercise:\n",
    "\n",
    "1. Experiment with different sizes for the random tensors and observe how it affects the histograms.\n",
    "2. Modify the code to create tensors using other random initialization functions, such as `torch.randint` or `torch.randperm`, and observe their distributions.\n",
    "\n",
    "Feel free to explore and visualize other random initialization functions available in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad6fac-e98a-412d-8e6a-3ef010cf6d12",
   "metadata": {},
   "source": [
    "# PyTorch nn.Module and LeNet-300-100 Model\n",
    "\n",
    "## PyTorch `nn.Module`\n",
    "\n",
    "In PyTorch, `nn.Module` is the base class for all neural network modules. It provides a convenient way to define, organize, and manage model parameters. Every neural network in PyTorch is built by subclassing `nn.Module` and implementing the `__init__` and `forward` methods.\n",
    "\n",
    "### Defining a Model with `nn.Module`\n",
    "\n",
    "Let's create a simple neural network using `nn.Module` with an example of the LeNet-300-100 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa59b5-d266-471e-aa5a-d9f0ce6468cb",
   "metadata": {},
   "source": [
    "#### Example: LeNet-300-100 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0649155-3957-4c0b-aee8-42fa283baf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input image\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the LeNet-300-100 model\n",
    "model = LeNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922c85b6-22c7-4455-ab78-5b6d72234089",
   "metadata": {},
   "source": [
    "In this example, `LeNet300` is a subclass of `nn.Module` with three linear layers. The `__init__` method initializes the layers, and the `forward` method defines the forward pass through the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838c10f-1f80-4dc1-8f0f-22e83f159f41",
   "metadata": {},
   "source": [
    "## Training Loop for LeNet-300-100 on MNIST Dataset\n",
    "\n",
    "In the following code snippet, we demonstrate a simple training loop for a LeNet-300-100 model on the MNIST dataset using PyTorch. The training loop includes loading the data, setting up the model, defining the loss function, and running the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727f5cb-ab27-4433-a250-bf9a89316a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to CUDA for GPU acceleration\n",
    "DEVICE = torch.device(\"cuda:0\")  # can use just \"cuda\" if u have a single GPU, or \"cpu\" if you want to train on cpu\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "torch.manual_seed(21)\n",
    "\n",
    "# Move the model to the specified device (GPU)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "# Define the loss function (CrossEntropyLoss)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Instantiate custom train and test datasets (not shown)\n",
    "train_data = Train()\n",
    "test_data = Val()\n",
    "\n",
    "# Create data loaders for train and test sets\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1024, shuffle=True,  num_workers=16, pin_memory=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,  batch_size=1024, shuffle=False, num_workers=16, pin_memory=True, drop_last=True)\n",
    "\n",
    "# Lists to store training statistics\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23202f3-1031-4aa6-9fe4-b24575d41394",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(10):\n",
    "    for x_data, y_data in train_loader:\n",
    "        # Move data to the specified device (GPU)\n",
    "        x_data, y_data = x_data.to(DEVICE), y_data.to(DEVICE)\n",
    "        y_data = torch.nn.functional.one_hot(y_data.long(), 10).float()\n",
    "        \n",
    "        # Zero the gradients, forward pass, backward pass, and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_data)\n",
    "        loss = loss_fn(outputs.float(), y_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate and store training and test accuracies for each epoch\n",
    "    train_accuracies.append(get_accuracy(model, train_loader, DEVICE))\n",
    "    test_accuracies.append(get_accuracy(model, test_loader, DEVICE))\n",
    "\n",
    "    # Store the loss for visualization\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02c5aa-8a9d-4f15-9ecc-a115b80ec6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282836c6-9f4b-4d2f-a170-787b0dcfb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies, label=\"train\")\n",
    "plt.plot(test_accuracies, label=\"test\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
